{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af30bd05",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe5a713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "y = cancer['target']\n",
    "X = cancer['data']\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "    X, y, stratify = y, random_state = 0\n",
    ")\n",
    "\n",
    "x_tr.shape, x_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77723d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02110f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                        ('dt3', dt3), ('dt5', dt5)])\n",
    "\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                        ('dt3', dt3), ('dt5', dt5)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56ea9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy : 98.12%\n",
      "hard Test Accuracy : 95.10%\n",
      "\n",
      "soft Train Accuracy : 99.53%\n",
      "soft Test Accuracy : 95.80%\n",
      "\n",
      "knn1 Train Accuracy : 94.60%\n",
      "knn1 Test Accuracy : 91.61%\n",
      "\n",
      "knn2 Train Accuracy : 95.77%\n",
      "knn2 Test Accuracy : 91.61%\n",
      "\n",
      "lr Train Accuracy : 96.71%\n",
      "lr Test Accuracy : 93.71%\n",
      "\n",
      "dt3 Train Accuracy : 97.65%\n",
      "dt3 Test Accuracy : 91.61%\n",
      "\n",
      "dt5 Train Accuracy : 100.00%\n",
      "dt5 Test Accuracy : 90.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_tr, y_tr) * 100\n",
    "    test_score = model.score(x_te, y_te) * 100\n",
    "    print(f'{name} Train Accuracy : {train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy : {test_score:.2f}%')    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d798d",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1647a",
   "metadata": {},
   "source": [
    "- tree계열들은 max_depth 파라미터를 무조건 가지고 있음\n",
    "- 앙상블 종류 4가지도 max_depth 가지고있음\n",
    "- 5, 4, 3 정도로 줄여서 성능비교..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3745d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9976525821596244, 0.951048951048951)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=5).fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb5e7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9976525821596244, 0.9370629370629371)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=4).fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf1e095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9788732394366197, 0.9230769230769231)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=3).fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a454c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,3,4는 test점수 차이가 별로 없음\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=2).fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)\n",
    "print('2,3,4는 test점수 차이가 별로 없음')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b768eb",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0137247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.958041958041958)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f74be7",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2a29631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()),\n",
    "              ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                          final_estimator=LogisticRegression()) # 최종모델(메타모델)\n",
    "\n",
    "model.fit(x_tr, y_tr).score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0a334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8a357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ed01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "678ee25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN 0.9920445505171042 0.9851851851851852\n",
      "Logistic 1.0 0.9666666666666667\n",
      "Decision 1.0 0.7203703703703703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "digits = load_digits()\n",
    "\n",
    "y = digits['target']\n",
    "X = digits['data']\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "    X, y, stratify = y, random_state = 0, test_size=0.3\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # K-NN\n",
    "# knn = KNeighborsClassifier(n_neighbors=3).fit(x_tr, y_tr)\n",
    "# print('K-NN', knn.score(x_tr, y_tr), knn.score(x_te, y_te))\n",
    "\n",
    "# # Logistic\n",
    "# lr = LogisticRegression(max_iter=10000).fit(x_tr, y_tr)\n",
    "# print('Logistic', lr.score(x_tr, y_tr), lr.score(x_te, y_te))\n",
    "\n",
    "# # Decision\n",
    "# dt = DecisionTreeClassifier(max_depth=5).fit(x_tr,y_tr)\n",
    "# print('Decision', lr.score(x_tr, y_tr), dt.score(x_te, y_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af3b9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# knn, lr, dt\n",
    "knn3 = KNeighborsClassifier(n_neighbors=5).fit(x_tr, y_tr)\n",
    "knn5 = KNeighborsClassifier(n_neighbors=3).fit(x_tr, y_tr)\n",
    "lr = LogisticRegression(max_iter=10000).fit(x_tr, y_tr)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3).fit(x_tr, y_tr)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5).fit(x_tr, y_tr)\n",
    "\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                        ('dt3', dt3), ('dt5', dt5)])\n",
    "\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                        ('dt3', dt3), ('dt5', dt5)], voting = 'soft')\n",
    "\n",
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "\n",
    "# for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     name = names[idx]\n",
    "#     train_score = model.score(x_tr, y_tr) * 100\n",
    "#     test_score = model.score(x_te, y_te) * 100\n",
    "#     print(f'{name} Train Accuracy : {train_score:.2f}%')\n",
    "#     print(f'{name} Test Accuracy : {test_score:.2f}%')    \n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f663eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf3 = RandomForestClassifier(max_depth=3).fit(x_tr, y_tr)\n",
    "rf5 = RandomForestClassifier(max_depth=5).fit(x_tr, y_tr)\n",
    "# model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eeae937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb1 = GradientBoostingClassifier(max_depth=1).fit(x_tr, y_tr)\n",
    "gb3 = GradientBoostingClassifier(max_depth=3).fit(x_tr, y_tr)\n",
    "\n",
    "# model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e08901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()),\n",
    "              ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "st = StackingClassifier(estimators=estimators,\n",
    "                          final_estimator=LogisticRegression()).fit(x_tr, y_tr) # 최종모델(메타모델)\n",
    "\n",
    "# model.score(x_tr, y_tr), model.score(x_te, y_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1185303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 비교\n",
    "model = [knn3,knn5,lr,dt3,dt5,hard,soft,rf3,rf5,gb1,gb3,st]\n",
    "names = ['KNN-3','KNN-5','LogisticRegression','DecisionTree-3','DecisionTree-5','Ensemble-voting(hard)',\n",
    "        'Ensemble-voting(soft)','Ensemble-bagging(randomforest-3)','Ensemble-bagging(randomforest-5)',\n",
    "         'Ensemble-boosting(GradientBoosting-1)','Ensemble-boosting(GradientBoosting-3)','Ensemble-stacking(rf,gb)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66da121b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DecisionTreeClassifier' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rl/1rszx_6s765__41xlbvwvlmw0000gn/T/ipykernel_30079/1307226780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{y}: {x.score(x_te,y_te)*100}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DecisionTreeClassifier' object is not iterable"
     ]
    }
   ],
   "source": [
    "bs=0\n",
    "for x,y in zip(model,names):\n",
    "    print(f'{y}: {x.score(x_te,y_te)*100}') \n",
    "    if bs < x.score(x_te,y_te):\n",
    "        bs = x.score(x_te,y_te)\n",
    "        bn = y\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print(f'가장 좋은 모델은: {bn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef2de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
